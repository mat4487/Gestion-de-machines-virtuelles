TP2 : Cluster Experiment sur le Wiki de Grid5000
\begin{lstlisting}
lien : http://www.grid5000.fr/mediawiki/index.php/Cluster_experiment

configuration du proxy:
étape1: liste les proxy configuré en http et https
	commande: echo http_proxy=$http_proxy ; echo https_proxy=$https_proxy
	résultat:
		http_proxy=
		https_proxy=

étape2: Initialisé le proxy
	commande: export http_proxy="http://proxy:3128" ; export https_proxy="http://proxy:3128"
	résultat:
		http_proxy=http://proxy:3128
		https_proxy=http://proxy:3128

récupération de la tarball hello
	 commande: wget --no-check-certificate https://gforge.inria.fr/frs/download.php/26756/hello.tgz
décompression de la tarballe
	 commande: tar -xvzf ~/hello.tgz -C ~/
___________________________________________________________________________
commande 	       	     résultat					   |
oarstat			     permet de voir toutes les sumissions de job   |
									   |
résultat de la commande:						   |
ob id     Name           User           Submission Date     S Queue	   |
---------- -------------- -------------- ------------------- - ----------  |
351629                    malexand       2012-01-26 08:15:14 R default     |
351635                    tbuchert       2012-01-26 09:45:47 R default     |
351637                    trakotoarivelo 2012-01-26 09:54:11 R default     |
351639                    lsarzyniec     2012-01-26 10:23:05 R default     |
351640                    ejeanvoine     2012-01-26 10:35:00 R default     |
351647                    mquinson       2012-01-26 11:03:16 R default     |
351464                    malexand       2012-01-24 08:34:10 W default     |
351632                    gbrand         2012-01-26 09:40:15 W default     |
351633                    gbrand         2012-01-26 09:40:18 W default     |
351644                    falvaresdeoliv 2012-01-26 10:47:15 W default     |
351645                    falvaresdeoliv 2012-01-26 10:47:20 W default     |
351650     Gridmix        pcosta         2012-01-26 12:02:23 W default     |
351651                    jmontanier     2012-01-26 14:18:20 W default     |
----------------------------------------------------------------------------
oarstat -f			liste avec détail chaque réservations
----------------------------------------------------------------------------
oarstat -f -j OAR_JOB_ID	liste le détail d'une réservation avec un job id
----------------------------------------------------------------------------
oarstat -s -j OAR_JOB_ID	montre le status d'un job spécific
----------------------------------------------------------------------------
oarstat -u LOGIN		montre les réservation d'un utilisateur
----------------------------------------------------------------------------
oarnodes			liste les propriétés du cluster
----------------------------------------------------------------------------
oarprint host -P host,cpu,core -F "host: % cpu: % core: %" -C+			
liste les propriété du noeud utilisé(a utilisé lors de l(utilisation d'un noeud)
----------------------------------------------------------------------------
oarstat -j OAR_JOB_ID -p | oarprint core -P host,cpuset,memcore -F "%[%] (%)" -f - | sort
idem mais peut ce lancer dans le fronted
----------------------------------------------------------------------------
oarsub -I			permet de réserver un noeud pour 1H

résultat:
jtournois@fnancy:~$ oarsub -I
[ADMISSION RULE] Set default walltime to 3600.
[ADMISSION RULE] Modify resource description with type constraints
Generate a job key...
OAR_JOB_ID=351654
Interactive mode : waiting...
Starting...
----------------------------------------------------------------------------
env | grep -i ^oar		liste les variables d'environement
----------------------------------------------------------------------------
cat $OAR_NODE_FILE		liste le noeud utilisé
----------------------------------------------------------------------------

étape3: lancement du script hello
	commande: ./run_hello.mpi
résultat:
Hello world from process (1) of (8) running on griffon-91.nancy.grid5000.fr
 (1) : I'm tired. I'm going to sleep a bit.
Hello world from process (2) of (8) running on griffon-91.nancy.grid5000.fr
 (2) : I'm tired. I'm going to sleep a bit.
Hello world from process (5) of (8) running on griffon-91.nancy.grid5000.fr
 (5) : I'm tired. I'm going to sleep a bit.
Hello world from process (6) of (8) running on griffon-91.nancy.grid5000.fr
 (6) : I'm tired. I'm going to sleep a bit.
Hello world from process (7) of (8) running on griffon-91.nancy.grid5000.fr
 (7) : I'm tired. I'm going to sleep a bit.
Hello world from process (3) of (8) running on griffon-91.nancy.grid5000.fr
 (3) : I'm tired. I'm going to sleep a bit.
Hello world from process (4) of (8) running on griffon-91.nancy.grid5000.fr
 (4) : I'm tired. I'm going to sleep a bit.
Hello world from process (8) of (8) running on griffon-91.nancy.grid5000.fr
 (8) : I'm tired. I'm going to sleep a bit.
 (5) : Mmmm... What? Ok, It was short but good :-)
 (6) : Mmmm... What? Ok, It was short but good :-)
 (7) : Mmmm... What? Ok, It was short but good :-)
 (2) : Mmmm... What? Ok, It was short but good :-)
 (1) : Mmmm... What? Ok, It was short but good :-)
 (8) : Mmmm... What? Ok, It was short but good :-)
 (4) : Mmmm... What? Ok, It was short but good :-)
 (3) : Mmmm... What? Ok, It was short but good :-)

test les processeur disponibles
----------------------------------------------------------------------------
 Ctrl-D or exit			exit du noeud
----------------------------------------------------------------------------
oarsub ~/hello/run_hello_mpi -O ~/hello_mpi.log
redirige la sortie dans un fichier
----------------------------------------------------------------------------
oarsub -C OAR_JOB_ID		connexion a un job existant
----------------------------------------------------------------------------
oarsub -I -l nodes=2		réservation de deux noeud
----------------------------------------------------------------------------
oarsh OTHER_NODE_HOSTNAME	connexion a un autre noeud
----------------------------------------------------------------------------
oarsh OTHER_NODE_HOSTNAME ps -C hello_mpi
permet de lancer le script sur un noeud distant
----------------------------------------------------------------------------
oarsub -I -t container -l nodes=4,walltime=0:45:00
réservation de 4 noeud pour 45 min
----------------------------------------------------------------------------
oarsub -I -t inner=containerJobID -l nodes=3,walltime=0:15:00
permet de rajuster la réservation précédente a 3 noeud pour 15min
----------------------------------------------------------------------------
oardel OAR_JOB_ID		supprime un job id
----------------------------------------------------------------------------
\end{lstlisting}
